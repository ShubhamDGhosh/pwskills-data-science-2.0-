{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0dba244b",
      "metadata": {
        "id": "0dba244b"
      },
      "source": [
        "# Machine Learning Assignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778a6035",
      "metadata": {
        "id": "778a6035"
      },
      "source": [
        "### Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "Overfitting occurs when a model learns the training data too well, capturing noise and outliers, which leads to poor generalization to new, unseen data.\n",
        "Underfitting happens when a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and test data.\n",
        "\n",
        "Mitigation:\n",
        "Overfitting: Use cross-validation, regularization, or simplify the model.\n",
        "Underfitting: Increase model complexity, use more relevant features, or reduce regularization."
      ],
      "metadata": {
        "id": "qAKhnnJoRRb8"
      },
      "id": "qAKhnnJoRRb8"
    },
    {
      "cell_type": "markdown",
      "id": "f91ebd1c",
      "metadata": {
        "id": "f91ebd1c"
      },
      "source": [
        "### Q2: How can we reduce overfitting? Explain in brief."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "Techniques to reduce overfitting include:\n",
        "Cross-validation: Helps to check if the model performs well on unseen data.\n",
        "Regularization: Adds a penalty to the model complexity (e.g., L1, L2 regularization).\n",
        "Pruning: In decision trees, reduce depth or prune unnecessary branches.\n",
        "Dropout: For neural networks, randomly drop units to avoid co-dependency.\n",
        "Increase training data: More data helps the model generalize better."
      ],
      "metadata": {
        "id": "vjfy2ICgRcJ_"
      },
      "id": "vjfy2ICgRcJ_"
    },
    {
      "cell_type": "markdown",
      "id": "3494e700",
      "metadata": {
        "id": "3494e700"
      },
      "source": [
        "### Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "Underfitting is when a model is too simple to capture the underlying structure in the data, leading to high bias and poor performance on both training and testing data.\n",
        "\n",
        "Scenarios where underfitting can occur:\n",
        "- Using a linear model for complex, non-linear data.\n",
        "- Too much regularization applied (e.g., high L2 penalty).\n",
        "- Insufficient features or not enough training iterations in models like neural networks."
      ],
      "metadata": {
        "id": "MWtnGr8RRhwD"
      },
      "id": "MWtnGr8RRhwD"
    },
    {
      "cell_type": "markdown",
      "id": "e1b0dd1c",
      "metadata": {
        "id": "e1b0dd1c"
      },
      "source": [
        "### Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "The bias-variance tradeoff describes the relationship between model complexity and prediction error:\n",
        "Bias: Error due to oversimplified models (e.g., underfitting) that cannot capture the dataâ€™s complexity.\n",
        "Variance: Error due to overly complex models (e.g., overfitting) that capture noise in the data.\n",
        "\n",
        "Relationship: As bias decreases with model complexity, variance tends to increase, and vice versa. The goal is to balance them for optimal performance."
      ],
      "metadata": {
        "id": "1g5qsoyrRoTO"
      },
      "id": "1g5qsoyrRoTO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.How can you determine whether your model is overfitting or underfitting?\n",
        "\n",
        "Answer:\n",
        "Detecting overfitting:\n",
        "- High accuracy on training data but poor performance on validation/test data.\n",
        "- Training loss continues to decrease, but validation loss increases.\n",
        "\n",
        "Detecting underfitting:\n",
        "- Both training and validation errors are high, indicating that the model is too simple.\n",
        "\n",
        "Methods:\n",
        "Cross-validation: Compare training and validation performance.\n",
        "Learning curves: Monitor the model's training and validation losses."
      ],
      "metadata": {
        "id": "2UHtdHH-RtDO"
      },
      "id": "2UHtdHH-RtDO"
    },
    {
      "cell_type": "markdown",
      "id": "bfd82223",
      "metadata": {
        "id": "bfd82223"
      },
      "source": [
        "### Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "High bias:\n",
        "Models: Linear regression, Logistic regression.\n",
        "Performance: Simplified models that may miss important patterns (underfitting).\n",
        "\n",
        "High variance:\n",
        "Models: Decision trees, k-nearest neighbors (KNN).\n",
        "Performance: Complex models that capture noise (overfitting).\n",
        "\n",
        "Difference:\n",
        "High bias models have poor accuracy on both training and test data.\n",
        "High variance models perform well on training data but poorly on unseen data."
      ],
      "metadata": {
        "id": "KSbVCcbpSHlw"
      },
      "id": "KSbVCcbpSHlw"
    },
    {
      "cell_type": "markdown",
      "id": "8ad0fa83",
      "metadata": {
        "id": "8ad0fa83"
      },
      "source": [
        "### Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
        "\n",
        "Answer:\n",
        "Regularization is a technique used to prevent overfitting by penalizing complex models.\n",
        "\n",
        "Common techniques:\n",
        "- L1 Regularization (Lasso): Adds an absolute value of weights to the loss function, encouraging sparsity in features.\n",
        "- L2 Regularization (Ridge): Adds the squared value of weights to the loss function, reducing the magnitude of weights and discouraging large coefficients.\n",
        "- ElasticNet: Combines both L1 and L2 regularization, offering a balance between sparsity and weight reduction.\n",
        "\n",
        "These techniques add a penalty to the loss function to control model complexity."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}